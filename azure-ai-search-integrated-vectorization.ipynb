{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure AI Search Integrated Vectorization \n",
    "\n",
    "Integrated vectorization takes a dependency on indexers and skillsets, using the Text Split skill for data chunking, and the AzureOpenAIEmbedding skill and your Azure OpenAI resource for embedding.\n",
    "\n",
    "This example uses PDFs from the data/documents folder for chunking, embedding, indexing and queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisites\n",
    "    1. An Azure subscription, with access to Azure OpenAI.\n",
    "    2. Azure AI Search, any tier, but we recommend Basic or higher for this workload. Enable semantic ranker if you want to run a hybrid query with semantic ranking.\n",
    "    3. A deployment of the text-embedding-ada-002 model on Azure OpenAI.\n",
    "    4. Azure Blob Storage. \n",
    "\n",
    "    Python interpreter with 3.10 or later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Users/sithukaungset/Azure-AI-Search-prompthon/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env file\n",
    "\n",
    "# Variables not used here do not need to be updated in your .env file\n",
    "endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "credential = AzureKeyCredential(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) if len(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) > 0 else DefaultAzureCredential()\n",
    "index_name = os.environ[\"AZURE_SEARCH_INDEX\"]\n",
    "blob_connection_string = os.environ[\"BLOB_CONNECTION_STRING\"]\n",
    "blob_container_name = os.environ[\"BLOB_CONTAINER_NAME\"]\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_key = os.environ[\"AZURE_OPENAI_KEY\"] if len(os.environ[\"AZURE_OPENAI_KEY\"]) > 0 else None\n",
    "azure_openai_embedding_deployment = os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the Blob Storage and load documents\n",
    "\n",
    "Retrieve documentes from Blob Storage. We can see the sample documents in data/documents folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup sample data in hdaoai\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient  \n",
    "import os\n",
    "\n",
    "# Connect to Blob Storage\n",
    "blob_service_client = BlobServiceClient.from_connection_string(blob_connection_string)\n",
    "container_client = blob_service_client.get_container_client(blob_container_name)\n",
    "if not container_client.exists():\n",
    "    container_client.create_container()\n",
    "\n",
    "documents_directory = os.path.join(\"data\", \"documents\")\n",
    "for file in os.listdir(documents_directory):\n",
    "    with open(os.path.join(documents_directory, file), \"rb\") as data:\n",
    "        name = os.path.basename(file)\n",
    "        if not container_client.get_blob_client(name).exists():\n",
    "            container_client.upload_blob(name=name, data=data)\n",
    "\n",
    "print(f\"Setup sample data in {blob_container_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a blob data source connector on Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source 'hdaoai-blob' created or updated\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection\n",
    ")\n",
    "from azure.search.documents.indexes._generated.models import NativeBlobSoftDeleteDeletionDetectionPolicy\n",
    "\n",
    "# Create a data source \n",
    "indexer_client = SearchIndexerClient(endpoint, credential)\n",
    "container = SearchIndexerDataContainer(name=blob_container_name)\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=f\"{index_name}-blob\",\n",
    "    type=\"azureblob\",\n",
    "    connection_string=blob_connection_string,\n",
    "    container=container,\n",
    "    data_deletion_detection_policy=NativeBlobSoftDeleteDeletionDetectionPolicy()\n",
    ")\n",
    "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a search index\n",
    "Vector and nonvector content is stored in a search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdaoai created\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIParameters,\n",
    "    SemanticConfiguration,\n",
    "    SemanticSearch,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SearchIndex\n",
    ")\n",
    "\n",
    "# Create a search index  \n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)  \n",
    "fields = [  \n",
    "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=True),  \n",
    "    SearchField(name=\"title\", type=SearchFieldDataType.String),  \n",
    "    SearchField(name=\"chunk_id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True, analyzer_name=\"keyword\"),  \n",
    "    SearchField(name=\"chunk\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),  \n",
    "    SearchField(name=\"vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),  \n",
    "]  \n",
    "  \n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(  \n",
    "            name=\"myHnsw\",  \n",
    "            parameters=HnswParameters(  \n",
    "                m=4,  \n",
    "                ef_construction=400,  \n",
    "                ef_search=500,  \n",
    "                metric=VectorSearchAlgorithmMetric.COSINE,  \n",
    "            ),  \n",
    "        ),  \n",
    "        ExhaustiveKnnAlgorithmConfiguration(  \n",
    "            name=\"myExhaustiveKnn\",  \n",
    "            parameters=ExhaustiveKnnParameters(  \n",
    "                metric=VectorSearchAlgorithmMetric.COSINE,  \n",
    "            ),  \n",
    "        ),  \n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer=\"myOpenAI\",  \n",
    "        ),  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myExhaustiveKnnProfile\",  \n",
    "            algorithm_configuration_name=\"myExhaustiveKnn\",  \n",
    "            vectorizer=\"myOpenAI\",  \n",
    "        ),  \n",
    "    ],  \n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            azure_open_ai_parameters=AzureOpenAIParameters(  \n",
    "                resource_uri=azure_openai_endpoint,  \n",
    "                deployment_id=azure_openai_embedding_deployment,  \n",
    "                api_key=azure_openai_key,  \n",
    "            ),  \n",
    "        ),  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "semantic_config = SemanticConfiguration(  \n",
    "    name=\"my-semantic-config\",  \n",
    "    prioritized_fields=SemanticPrioritizedFields(  \n",
    "        content_fields=[SemanticField(field_name=\"chunk\")]  \n",
    "    ),  \n",
    ")  \n",
    "  \n",
    "# Create the semantic search with the configuration  \n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])  \n",
    "  \n",
    "# Create the search index\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)  \n",
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} created\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a skillset\n",
    "\n",
    "Skills drive integrated vectorization. Text Split provides data chunking. Azure OpenAI Embedding handles calls to the Azure OpenAI, using the connection in env file. An indexer projection specifies secondary indexes used for chunked data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdaoai-skillset created\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SplitSkill,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    SearchIndexerIndexProjections,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    IndexProjectionMode,\n",
    "    SearchIndexerSkillset\n",
    ")\n",
    "\n",
    "# Create a skillset  \n",
    "skillset_name = f\"{index_name}-skillset\"  \n",
    "  \n",
    "split_skill = SplitSkill(  \n",
    "    description=\"Split skill to chunk documents\",  \n",
    "    text_split_mode=\"pages\",  \n",
    "    context=\"/document\",  \n",
    "    maximum_page_length=2000,  \n",
    "    page_overlap_length=500,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/content\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "    description=\"Skill to generate embeddings via Azure OpenAI\",  \n",
    "    context=\"/document/pages/*\",  \n",
    "    resource_uri=azure_openai_endpoint,  \n",
    "    deployment_id=azure_openai_embedding_deployment,  \n",
    "    api_key=azure_openai_key,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"vector\")  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "index_projections = SearchIndexerIndexProjections(  \n",
    "    selectors=[  \n",
    "        SearchIndexerIndexProjectionSelector(  \n",
    "            target_index_name=index_name,  \n",
    "            parent_key_field_name=\"parent_id\",  \n",
    "            source_context=\"/document/pages/*\",  \n",
    "            mappings=[  \n",
    "                InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*\"),  \n",
    "                InputFieldMappingEntry(name=\"vector\", source=\"/document/pages/*/vector\"),  \n",
    "                InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),  \n",
    "            ],  \n",
    "        ),  \n",
    "    ],  \n",
    "    parameters=SearchIndexerIndexProjectionsParameters(  \n",
    "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS  \n",
    "    ),  \n",
    ")  \n",
    "  \n",
    "skillset = SearchIndexerSkillset(  \n",
    "    name=skillset_name,  \n",
    "    description=\"Skillset to chunk documents and generating embeddings\",  \n",
    "    skills=[split_skill, embedding_skill],  \n",
    "    index_projections=index_projections,  \n",
    ")  \n",
    "  \n",
    "client = SearchIndexerClient(endpoint, credential)  \n",
    "client.create_or_update_skillset(skillset)  \n",
    "print(f\"{skillset.name} created\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hdaoai-indexer is created and running. If queries return no results, please wait a bit and try again.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexer,\n",
    "    FieldMapping\n",
    ")\n",
    "\n",
    "# Create an indexer  \n",
    "indexer_name = f\"{index_name}-indexer\"  \n",
    "  \n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to index documents and generate embeddings\",  \n",
    "    skillset_name=skillset_name,  \n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name,  \n",
    "    # Map the metadata_storage_name field to the title field in the index to display the PDF title in the search results  \n",
    "    field_mappings=[FieldMapping(source_field_name=\"metadata_storage_name\", target_field_name=\"title\")]  \n",
    ")  \n",
    "  \n",
    "indexer_client = SearchIndexerClient(endpoint, credential)  \n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
    "  \n",
    "# Run the indexer  \n",
    "indexer_client.run_indexer(indexer_name)  \n",
    "print(f' {indexer_name} is created and running. If queries return no results, please wait a bit and try again.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a vector similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_id: aHR0cHM6Ly9hb2FpdGVhbWJsb2JzdG9yYWdlLmJsb2IuY29yZS53aW5kb3dzLm5ldC9oZGFvYWkvUFBUJUVDJTgzJTk4JUVEJTk0JThDKCVFRCU5NSU5QyVFQSVCOCU4MClfJUVDJTg0JUI4JUVCJUFGJUI4JUVCJTgyJTk4JUVCJUIwJTlDJUVEJTkxJTlDLnBwdHg1\n",
      "chunk_id: 742299af0127_aHR0cHM6Ly9hb2FpdGVhbWJsb2JzdG9yYWdlLmJsb2IuY29yZS53aW5kb3dzLm5ldC9oZGFvYWkvUFBUJUVDJTgzJTk4JUVEJTk0JThDKCVFRCU5NSU5QyVFQSVCOCU4MClfJUVDJTg0JUI4JUVCJUFGJUI4JUVCJTgyJTk4JUVCJUIwJTlDJUVEJTkxJTlDLnBwdHg1_pages_0\n",
      "Score: 0.8358228\n",
      "Content: 01. Demo Session 1 – AOAI 기반 RDB연동 Chatbot (회의실 예약 시스템)\n",
      "TO-BE) AOAI의 지능화된 연계기술(Function calling)을 통해 Legacy 시스템과 연계하고,\n",
      "대화를 통한 추천 방식으로 전환하여 단계별로 진행되던 업무과정을 혁신적으로 간소화 할 수 있습니다.\n",
      "\n",
      "회의실 예약업무 문제 해결 과정\n",
      "RDB 연동 LLM Chatbot 구성현황\n",
      "\n",
      "예약신청\n",
      "예약취소\n",
      "예약변경\n",
      "회의실 전체현황\n",
      "조회\n",
      "회의실 조건 검색\n",
      "대안 고민\n",
      "(회의실 없는 경우)\n",
      "반복적 고민\n",
      "(인원, 빈회의실,회의환경)\n",
      "\n",
      "\n",
      "기존\n",
      "문제\n",
      "개선\n",
      "시간 소요\n",
      "(매번 동일한\n",
      "조건으로 입력)\n",
      "단계적인 수행없이 One-Stop 업무처리 가능한 방식으로 개선 됨\n",
      "변화) 검색방식  대화, 추천 방식\n",
      "효과) 2분  30초 (75% 단축)\n",
      "\n",
      "IT(DB)와 연동된 Chatbot 동작 구조\n",
      "\n",
      "“내일 회의실 좀 예약해줘”\n",
      "지난주에 하신 “TF 주간회의“\n",
      "시면 6번 Room으로 오전 9시반 예약해 드릴까요?\n",
      "“오늘 회의 취소 됬어”\n",
      "“회의 어디서 하지?”\n",
      "오후 3시 예약된 “OO이슈회의”\n",
      "취소해 드릴까요?\n",
      "10분 후 참석할 “OO회의”\n",
      "장소는 “Room5번”입니다.\n",
      "네\n",
      "\n",
      "\n",
      "기업 내 정보시스템\n",
      "정형 데이터\n",
      "(RDBMS, SAP 등)\n",
      "\n",
      "\n",
      "One-Stop처리\n",
      "(추천 방식)\n",
      "\n",
      "VOC 처리\n",
      "인사제도\n",
      "Q&A\n",
      "회의실 예약\n",
      "생성형 AI 서비스 플랫폼\n",
      "\n",
      "\n",
      "\n",
      "AOAI\n",
      "LLM\n",
      "\n",
      "\n",
      "AI Studio\n",
      "(AI개발환경)\n",
      "\n",
      "\n",
      "Copilot\n",
      "Studio\n",
      "임직원\n",
      "※ 지능화된 AOAI 연동방식\n",
      "     - Function Calling\n",
      "\n",
      "\n",
      "Copyright 2024 ⓒ MegazoneCloud. ALL RIGHT RESERVED.\n",
      "\n",
      "기존의 회의실 예약 시스템을 사용할 때, 직원들은 종종 반복적이고 사소한 결정을 내려야 했습니다. \n",
      "적절한 크기의 회의실을 찾고, 사용 가능한 시간을 조정하며, 필요한 경우 회의 장소를 다시 검색하는 등의 과정이 필요했죠. \n",
      "이제 Copilot이 이러한 과정을 어떻게 간소화해주는지 살펴보겠습니다. \n",
      "요청은 간단합니다: '내일 회의실 예약해줘'. Copilot은 사용자의 예약 패턴을 분석하여 신속하게 적절한 회의실을 추천해줍니다. \n",
      "이는 매우 개인화된 서비스입니다. '오늘 회의 취소됐어'라고 말하면, Copilot은 맥락을 이해하고 회의실 예약을 취소하는 것을 제안합니다.\n",
      "이처럼, 기존에 순차적으로 진행되던 예약 관련 업무가 Copilot을 통해 '원샷 추천 방식'으로 전환되어 업무 처리 시간이 최대 75%까지 단축될 수 있습니다. \n",
      "이제 실제 데모를 통해 Copilot의 이러한 기능을 직접 체험해 보시겠습니다.\n",
      "1\n",
      "\n",
      "\n",
      "02. Demo Session 2 – Copilot Studio 기반 쉬운 검색 서비스\n",
      "Copilot Studio(Chatbot)와 Bing Search(포털검색) 기능을 통합하여, 회사 내부 문서는 물론 외부의 지정된 웹사이트와 포털 검색 결과까지 대화 형태로 질문하고 답변을 받을 수 있는 서비스입니다.\n",
      "\n",
      "적용결과 화면\n",
      "주요 기능\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "내 외부의 풍부한 정보를 기반으로 지능화된 Q&A 답변 제공\n",
      "다양한 문서\n",
      "지정된 웹사이트\n",
      "실시간 포털 검색 (Bing Search)\n",
      "문서정보 (PDF, Word 등)\n",
      "Website\n",
      "(지정된)\n",
      "\n",
      "\n",
      "실시간 검색\n",
      "\n",
      "Vector\n",
      "Store\n",
      "\n",
      "\n",
      "Copilot Studio\n",
      "(Chatbot)\n",
      "ChatGPT\n",
      "AI Search\n",
      "(지식검색)\n",
      "기업 내부 정보\n",
      "기업 외부 정보\n",
      "User\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(MZC MTA AOAI팀) 홍길동\n",
      "월 별 파견지 교통비 한도가 어떻게 되지?\n",
      "\n",
      "\n",
      "\n",
      "(MZC MTA AOAI팀) 홍길동\n",
      "OpenAI Dev Conference 발표내용을 Bing Search를 이용해서 찾아줘\n",
      "\n",
      "\n",
      "\n",
      "월 별 파견지 교통비 한도는 70만원이고 초과 시에는 정산이 불가합니다.\n",
      "(HR) MegaChat\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "OpenAI DevDay는 OpenAI가 주최한 첫 개발자 컨퍼런스로, 2023년 11월6일 샌프란시스코에서 개최되었습니다. 이 컨퍼런스에 대한 자세한 정보는 다음 링크를 통해서 확인할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "\n",
    "# Pure Vector Search\n",
    "query = \"지능화된 연계기술\"  \n",
    "  \n",
    "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"vector\", exhaustive=True)\n",
    "# Use the below query to pass in the raw vector query instead of the query vectorization\n",
    "# vector_query = RawVectorQuery(vector=generate_embeddings(query), k_nearest_neighbors=3, fields=\"vector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
    "    top=1\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['chunk']}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_id: aHR0cHM6Ly9hb2FpdGVhbWJsb2JzdG9yYWdlLmJsb2IuY29yZS53aW5kb3dzLm5ldC9oZGFvYWkvUFBUJUVDJTgzJTk4JUVEJTk0JThDKCVFRCU5NSU5QyVFQSVCOCU4MClfJUVDJTg0JUI4JUVCJUFGJUI4JUVCJTgyJTk4JUVCJUIwJTlDJUVEJTkxJTlDLnBwdHg1\n",
      "chunk_id: 742299af0127_aHR0cHM6Ly9hb2FpdGVhbWJsb2JzdG9yYWdlLmJsb2IuY29yZS53aW5kb3dzLm5ldC9oZGFvYWkvUFBUJUVDJTgzJTk4JUVEJTk0JThDKCVFRCU5NSU5QyVFQSVCOCU4MClfJUVDJTg0JUI4JUVCJUFGJUI4JUVCJTgyJTk4JUVCJUIwJTlDJUVEJTkxJTlDLnBwdHg1_pages_0\n",
      "Score: 0.03333333507180214\n",
      "Content: 01. Demo Session 1 – AOAI 기반 RDB연동 Chatbot (회의실 예약 시스템)\n",
      "TO-BE) AOAI의 지능화된 연계기술(Function calling)을 통해 Legacy 시스템과 연계하고,\n",
      "대화를 통한 추천 방식으로 전환하여 단계별로 진행되던 업무과정을 혁신적으로 간소화 할 수 있습니다.\n",
      "\n",
      "회의실 예약업무 문제 해결 과정\n",
      "RDB 연동 LLM Chatbot 구성현황\n",
      "\n",
      "예약신청\n",
      "예약취소\n",
      "예약변경\n",
      "회의실 전체현황\n",
      "조회\n",
      "회의실 조건 검색\n",
      "대안 고민\n",
      "(회의실 없는 경우)\n",
      "반복적 고민\n",
      "(인원, 빈회의실,회의환경)\n",
      "\n",
      "\n",
      "기존\n",
      "문제\n",
      "개선\n",
      "시간 소요\n",
      "(매번 동일한\n",
      "조건으로 입력)\n",
      "단계적인 수행없이 One-Stop 업무처리 가능한 방식으로 개선 됨\n",
      "변화) 검색방식  대화, 추천 방식\n",
      "효과) 2분  30초 (75% 단축)\n",
      "\n",
      "IT(DB)와 연동된 Chatbot 동작 구조\n",
      "\n",
      "“내일 회의실 좀 예약해줘”\n",
      "지난주에 하신 “TF 주간회의“\n",
      "시면 6번 Room으로 오전 9시반 예약해 드릴까요?\n",
      "“오늘 회의 취소 됬어”\n",
      "“회의 어디서 하지?”\n",
      "오후 3시 예약된 “OO이슈회의”\n",
      "취소해 드릴까요?\n",
      "10분 후 참석할 “OO회의”\n",
      "장소는 “Room5번”입니다.\n",
      "네\n",
      "\n",
      "\n",
      "기업 내 정보시스템\n",
      "정형 데이터\n",
      "(RDBMS, SAP 등)\n",
      "\n",
      "\n",
      "One-Stop처리\n",
      "(추천 방식)\n",
      "\n",
      "VOC 처리\n",
      "인사제도\n",
      "Q&A\n",
      "회의실 예약\n",
      "생성형 AI 서비스 플랫폼\n",
      "\n",
      "\n",
      "\n",
      "AOAI\n",
      "LLM\n",
      "\n",
      "\n",
      "AI Studio\n",
      "(AI개발환경)\n",
      "\n",
      "\n",
      "Copilot\n",
      "Studio\n",
      "임직원\n",
      "※ 지능화된 AOAI 연동방식\n",
      "     - Function Calling\n",
      "\n",
      "\n",
      "Copyright 2024 ⓒ MegazoneCloud. ALL RIGHT RESERVED.\n",
      "\n",
      "기존의 회의실 예약 시스템을 사용할 때, 직원들은 종종 반복적이고 사소한 결정을 내려야 했습니다. \n",
      "적절한 크기의 회의실을 찾고, 사용 가능한 시간을 조정하며, 필요한 경우 회의 장소를 다시 검색하는 등의 과정이 필요했죠. \n",
      "이제 Copilot이 이러한 과정을 어떻게 간소화해주는지 살펴보겠습니다. \n",
      "요청은 간단합니다: '내일 회의실 예약해줘'. Copilot은 사용자의 예약 패턴을 분석하여 신속하게 적절한 회의실을 추천해줍니다. \n",
      "이는 매우 개인화된 서비스입니다. '오늘 회의 취소됐어'라고 말하면, Copilot은 맥락을 이해하고 회의실 예약을 취소하는 것을 제안합니다.\n",
      "이처럼, 기존에 순차적으로 진행되던 예약 관련 업무가 Copilot을 통해 '원샷 추천 방식'으로 전환되어 업무 처리 시간이 최대 75%까지 단축될 수 있습니다. \n",
      "이제 실제 데모를 통해 Copilot의 이러한 기능을 직접 체험해 보시겠습니다.\n",
      "1\n",
      "\n",
      "\n",
      "02. Demo Session 2 – Copilot Studio 기반 쉬운 검색 서비스\n",
      "Copilot Studio(Chatbot)와 Bing Search(포털검색) 기능을 통합하여, 회사 내부 문서는 물론 외부의 지정된 웹사이트와 포털 검색 결과까지 대화 형태로 질문하고 답변을 받을 수 있는 서비스입니다.\n",
      "\n",
      "적용결과 화면\n",
      "주요 기능\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "내 외부의 풍부한 정보를 기반으로 지능화된 Q&A 답변 제공\n",
      "다양한 문서\n",
      "지정된 웹사이트\n",
      "실시간 포털 검색 (Bing Search)\n",
      "문서정보 (PDF, Word 등)\n",
      "Website\n",
      "(지정된)\n",
      "\n",
      "\n",
      "실시간 검색\n",
      "\n",
      "Vector\n",
      "Store\n",
      "\n",
      "\n",
      "Copilot Studio\n",
      "(Chatbot)\n",
      "ChatGPT\n",
      "AI Search\n",
      "(지식검색)\n",
      "기업 내부 정보\n",
      "기업 외부 정보\n",
      "User\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(MZC MTA AOAI팀) 홍길동\n",
      "월 별 파견지 교통비 한도가 어떻게 되지?\n",
      "\n",
      "\n",
      "\n",
      "(MZC MTA AOAI팀) 홍길동\n",
      "OpenAI Dev Conference 발표내용을 Bing Search를 이용해서 찾아줘\n",
      "\n",
      "\n",
      "\n",
      "월 별 파견지 교통비 한도는 70만원이고 초과 시에는 정산이 불가합니다.\n",
      "(HR) MegaChat\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "OpenAI DevDay는 OpenAI가 주최한 첫 개발자 컨퍼런스로, 2023년 11월6일 샌프란시스코에서 개최되었습니다. 이 컨퍼런스에 대한 자세한 정보는 다음 링크를 통해서 확인할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Search\n",
    "query = \"지능화된 연계기술\"  \n",
    "  \n",
    "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"vector\", exhaustive=True)\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
    "    top=1\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['chunk']}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a hybrid search + semantic reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_id: aHR0cHM6Ly9hb2FpdGVhbWJsb2JzdG9yYWdlLmJsb2IuY29yZS53aW5kb3dzLm5ldC9oZGFvYWkvUFBUJUVDJTgzJTk4JUVEJTk0JThDKCVFRCU5NSU5QyVFQSVCOCU4MClfJUVDJTg0JUI4JUVCJUFGJUI4JUVCJTgyJTk4JUVCJUIwJTlDJUVEJTkxJTlDLnBwdHg1\n",
      "chunk_id: 742299af0127_aHR0cHM6Ly9hb2FpdGVhbWJsb2JzdG9yYWdlLmJsb2IuY29yZS53aW5kb3dzLm5ldC9oZGFvYWkvUFBUJUVDJTgzJTk4JUVEJTk0JThDKCVFRCU5NSU5QyVFQSVCOCU4MClfJUVDJTg0JUI4JUVCJUFGJUI4JUVCJTgyJTk4JUVCJUIwJTlDJUVEJTkxJTlDLnBwdHg1_pages_0\n",
      "Reranker Score: 3.3512561321258545\n",
      "Content: 01. Demo Session 1 – AOAI 기반 RDB연동 Chatbot (회의실 예약 시스템)\n",
      "TO-BE) AOAI의 지능화된 연계기술(Function calling)을 통해 Legacy 시스템과 연계하고,\n",
      "대화를 통한 추천 방식으로 전환하여 단계별로 진행되던 업무과정을 혁신적으로 간소화 할 수 있습니다.\n",
      "\n",
      "회의실 예약업무 문제 해결 과정\n",
      "RDB 연동 LLM Chatbot 구성현황\n",
      "\n",
      "예약신청\n",
      "예약취소\n",
      "예약변경\n",
      "회의실 전체현황\n",
      "조회\n",
      "회의실 조건 검색\n",
      "대안 고민\n",
      "(회의실 없는 경우)\n",
      "반복적 고민\n",
      "(인원, 빈회의실,회의환경)\n",
      "\n",
      "\n",
      "기존\n",
      "문제\n",
      "개선\n",
      "시간 소요\n",
      "(매번 동일한\n",
      "조건으로 입력)\n",
      "단계적인 수행없이 One-Stop 업무처리 가능한 방식으로 개선 됨\n",
      "변화) 검색방식  대화, 추천 방식\n",
      "효과) 2분  30초 (75% 단축)\n",
      "\n",
      "IT(DB)와 연동된 Chatbot 동작 구조\n",
      "\n",
      "“내일 회의실 좀 예약해줘”\n",
      "지난주에 하신 “TF 주간회의“\n",
      "시면 6번 Room으로 오전 9시반 예약해 드릴까요?\n",
      "“오늘 회의 취소 됬어”\n",
      "“회의 어디서 하지?”\n",
      "오후 3시 예약된 “OO이슈회의”\n",
      "취소해 드릴까요?\n",
      "10분 후 참석할 “OO회의”\n",
      "장소는 “Room5번”입니다.\n",
      "네\n",
      "\n",
      "\n",
      "기업 내 정보시스템\n",
      "정형 데이터\n",
      "(RDBMS, SAP 등)\n",
      "\n",
      "\n",
      "One-Stop처리\n",
      "(추천 방식)\n",
      "\n",
      "VOC 처리\n",
      "인사제도\n",
      "Q&A\n",
      "회의실 예약\n",
      "생성형 AI 서비스 플랫폼\n",
      "\n",
      "\n",
      "\n",
      "AOAI\n",
      "LLM\n",
      "\n",
      "\n",
      "AI Studio\n",
      "(AI개발환경)\n",
      "\n",
      "\n",
      "Copilot\n",
      "Studio\n",
      "임직원\n",
      "※ 지능화된 AOAI 연동방식\n",
      "     - Function Calling\n",
      "\n",
      "\n",
      "Copyright 2024 ⓒ MegazoneCloud. ALL RIGHT RESERVED.\n",
      "\n",
      "기존의 회의실 예약 시스템을 사용할 때, 직원들은 종종 반복적이고 사소한 결정을 내려야 했습니다. \n",
      "적절한 크기의 회의실을 찾고, 사용 가능한 시간을 조정하며, 필요한 경우 회의 장소를 다시 검색하는 등의 과정이 필요했죠. \n",
      "이제 Copilot이 이러한 과정을 어떻게 간소화해주는지 살펴보겠습니다. \n",
      "요청은 간단합니다: '내일 회의실 예약해줘'. Copilot은 사용자의 예약 패턴을 분석하여 신속하게 적절한 회의실을 추천해줍니다. \n",
      "이는 매우 개인화된 서비스입니다. '오늘 회의 취소됐어'라고 말하면, Copilot은 맥락을 이해하고 회의실 예약을 취소하는 것을 제안합니다.\n",
      "이처럼, 기존에 순차적으로 진행되던 예약 관련 업무가 Copilot을 통해 '원샷 추천 방식'으로 전환되어 업무 처리 시간이 최대 75%까지 단축될 수 있습니다. \n",
      "이제 실제 데모를 통해 Copilot의 이러한 기능을 직접 체험해 보시겠습니다.\n",
      "1\n",
      "\n",
      "\n",
      "02. Demo Session 2 – Copilot Studio 기반 쉬운 검색 서비스\n",
      "Copilot Studio(Chatbot)와 Bing Search(포털검색) 기능을 통합하여, 회사 내부 문서는 물론 외부의 지정된 웹사이트와 포털 검색 결과까지 대화 형태로 질문하고 답변을 받을 수 있는 서비스입니다.\n",
      "\n",
      "적용결과 화면\n",
      "주요 기능\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "내 외부의 풍부한 정보를 기반으로 지능화된 Q&A 답변 제공\n",
      "다양한 문서\n",
      "지정된 웹사이트\n",
      "실시간 포털 검색 (Bing Search)\n",
      "문서정보 (PDF, Word 등)\n",
      "Website\n",
      "(지정된)\n",
      "\n",
      "\n",
      "실시간 검색\n",
      "\n",
      "Vector\n",
      "Store\n",
      "\n",
      "\n",
      "Copilot Studio\n",
      "(Chatbot)\n",
      "ChatGPT\n",
      "AI Search\n",
      "(지식검색)\n",
      "기업 내부 정보\n",
      "기업 외부 정보\n",
      "User\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(MZC MTA AOAI팀) 홍길동\n",
      "월 별 파견지 교통비 한도가 어떻게 되지?\n",
      "\n",
      "\n",
      "\n",
      "(MZC MTA AOAI팀) 홍길동\n",
      "OpenAI Dev Conference 발표내용을 Bing Search를 이용해서 찾아줘\n",
      "\n",
      "\n",
      "\n",
      "월 별 파견지 교통비 한도는 70만원이고 초과 시에는 정산이 불가합니다.\n",
      "(HR) MegaChat\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "OpenAI DevDay는 OpenAI가 주최한 첫 개발자 컨퍼런스로, 2023년 11월6일 샌프란시스코에서 개최되었습니다. 이 컨퍼런스에 대한 자세한 정보는 다음 링크를 통해서 확인할 수 있습니다.\n",
      "Caption: 01. Demo Session 1 – AOAI 기반 RDB연동 Chatbot (회의실 예약 시스템) TO-BE) AOAI의 지능화된 연계기술(Function calling)을 통해 Legacy 시스템과 연계하고, 대화를 통한 추천 방식으로 전환하여 단계별로 진행되던 업무과정을 혁신적으로 간소화 할 수 있습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.models import (\n",
    "    QueryType,\n",
    "    QueryCaptionType,\n",
    "    QueryAnswerType\n",
    ")\n",
    "# Semantic Hybrid Search\n",
    "query = \"지능화된 연계기술?\"\n",
    "\n",
    "search_client = SearchClient(endpoint, index_name, credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"vector\", exhaustive=True)\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    semantic_configuration_name='my-semantic-config',\n",
    "    query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "    query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=1\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "if semantic_answers:\n",
    "    for answer in semantic_answers:\n",
    "        if answer.highlights:\n",
    "            print(f\"Semantic Answer: {answer.highlights}\")\n",
    "        else:\n",
    "            print(f\"Semantic Answer: {answer.text}\")\n",
    "        print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"Content: {result['chunk']}\")  \n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
