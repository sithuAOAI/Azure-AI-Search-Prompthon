{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure AI Search with LlamaIndex\n",
    "\n",
    "This code demonstrates how to use Azure AI Search with Azure OpenAI and the LlamaIndex data framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Users/sithukaungset/Azure-AI-Search-prompthon/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "# Make sure your .env file has values for the following environment variables\n",
    "endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "credential = AzureKeyCredential(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) if len(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) > 0 else DefaultAzureCredential()\n",
    "index_name = os.environ[\"AZURE_SEARCH_INDEX\"]\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "# Llama Index does not support RBAC authentication, an API key is required\n",
    "azure_openai_key = os.environ[\"AZURE_OPENAI_KEY\"]\n",
    "if len(azure_openai_key) == 0:\n",
    "    raise Exception(\"API key required\")\n",
    "azure_openai_embedding_model = os.environ[\"AZURE_OPENAI_EMBEDDING_MODEL_NAME\"]\n",
    "azure_openai_embedding_deployment = os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"]\n",
    "azure_openai_chatgpt_deployment = os.environ[\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\"]\n",
    "azure_openai_api_version = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "embedding_dimensions = os.environ[\"AZURE_OPENAI_EMBEDDING_DIMENSIONS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure an embeddings instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "\n",
    "embeddings = AzureOpenAIEmbedding(\n",
    "    model_name=azure_openai_embedding_model,\n",
    "    deployment_name=azure_openai_embedding_deployment,\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_key\n",
    ")\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=azure_openai_chatgpt_deployment,\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload, vectorize, and index documents\n",
    "\n",
    "This step reads PDFs from a local folder, calls the embedding model for vectorization, and then calls a search client to index the content on Azure AI Search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Directory /Users/data/documents does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m Settings\u001b[38;5;241m.\u001b[39membed_model \u001b[38;5;241m=\u001b[39m embeddings\n\u001b[1;32m     29\u001b[0m directory \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 30\u001b[0m documents \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleDirectoryReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[1;32m     31\u001b[0m index \u001b[38;5;241m=\u001b[39m VectorStoreIndex\u001b[38;5;241m.\u001b[39mfrom_documents(\n\u001b[1;32m     32\u001b[0m     documents\u001b[38;5;241m=\u001b[39mdocuments,\n\u001b[1;32m     33\u001b[0m     storage_context\u001b[38;5;241m=\u001b[39mstorage_context)\n",
      "File \u001b[0;32m~/Azure-AI-Search-prompthon/venv/lib/python3.10/site-packages/llama_index/core/readers/file/base.py:220\u001b[0m, in \u001b[0;36mSimpleDirectoryReader.__init__\u001b[0;34m(self, input_dir, input_files, exclude, exclude_hidden, errors, recursive, encoding, filename_as_id, required_exts, file_extractor, num_files_limit, file_metadata, raise_on_error, fs)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_dir:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39misdir(input_dir):\n\u001b[0;32m--> 220\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dir \u001b[38;5;241m=\u001b[39m _Path(input_dir)\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexclude \u001b[38;5;241m=\u001b[39m exclude\n",
      "\u001b[0;31mValueError\u001b[0m: Directory /Users/data/documents does not exist."
     ]
    }
   ],
   "source": [
    "\n",
    "from llama_index.vector_stores.azureaisearch import AzureAISearchVectorStore, IndexManagement, MetadataIndexFieldType\n",
    "from llama_index.core import StorageContext, VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core import Settings\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "metadata_fields = {\n",
    "    \"author\": \"author\",\n",
    "    \"theme\": (\"topic\", MetadataIndexFieldType.STRING),\n",
    "    \"director\": \"director\",\n",
    "}\n",
    "\n",
    "vector_store = AzureAISearchVectorStore(  \n",
    "    search_or_index_client=SearchIndexClient(endpoint=endpoint, credential=credential),  \n",
    "    filterable_metadata_field_keys=metadata_fields,\n",
    "    index_name=index_name,  \n",
    "    index_management=IndexManagement.CREATE_IF_NOT_EXISTS,  \n",
    "    id_field_key=\"id\",  \n",
    "    chunk_field_key=\"content\",  \n",
    "    embedding_field_key=\"content_vector\",  \n",
    "    metadata_string_field_key=\"metadata\",\n",
    "    doc_id_field_key=\"doc_id\",\n",
    "    embedding_dimensionality=embedding_dimensions,\n",
    "    language_analyzer=\"en.lucene\",\n",
    "    vector_algorithm_type=\"exhaustiveKnn\"\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embeddings\n",
    "directory = os.path.abspath(os.path.join(\"..\", \"data\", \"documents\"))\n",
    "documents = SimpleDirectoryReader(directory).load_data()\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=documents,\n",
    "    storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a vector similarity search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(llm)\n",
    "response = query_engine.query(\"What is included in my Northwind Health Plus plan that is not in standard?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
